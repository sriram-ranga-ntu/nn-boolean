{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "LR9VvbHi1Ol6",
    "outputId": "7221c941-ebab-42bb-8a1e-0dbea63c5d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 999 ||WeightFunction-I|| Error: tensor(0.0200, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 0.7684,  0.0387,  0.1464,  0.0242],\n",
      "        [ 0.0629,  0.8018, -0.0838, -0.0204],\n",
      "        [ 0.2391, -0.1139,  0.6665,  0.0148],\n",
      "        [-0.0608, -0.0063,  0.0724,  0.9605]], grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.7484, -0.1304,  0.4822, -0.0352],\n",
      "        [ 0.0666,  0.9112,  0.0936,  0.2674],\n",
      "        [ 0.0968,  0.3443, -0.4541, -0.6413],\n",
      "        [ 0.4027,  0.1218, -0.1884,  0.6211]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8573,  0.0483,  0.2960,  0.2356],\n",
      "        [-0.0630,  0.7437,  0.3331,  0.0100],\n",
      "        [ 0.5548,  0.2841, -0.5817, -0.5748],\n",
      "        [-0.3140,  0.0829, -0.6780,  0.7930]], requires_grad=True)\n",
      "Step: 1999 ||WeightFunction-I|| Error: tensor(9.3683e-07, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 9.9967e-01,  3.0348e-04, -8.9198e-05, -2.0683e-05],\n",
      "        [ 3.9765e-05,  9.9737e-01, -3.6532e-04, -4.3188e-04],\n",
      "        [ 8.2767e-04, -2.4938e-03,  9.9929e-01,  1.6093e-06],\n",
      "        [-2.5961e-04,  1.6764e-04,  2.0781e-04,  9.9988e-01]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8138, -0.1409,  0.4279, -0.0253],\n",
      "        [-0.0052,  1.0395,  0.2152,  0.2397],\n",
      "        [ 0.1650,  0.3354, -0.5789, -0.5862],\n",
      "        [ 0.5197,  0.0581, -0.3225,  0.6798]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8863, -0.0364,  0.4153,  0.4035],\n",
      "        [-0.0368,  0.8553,  0.3131, -0.0326],\n",
      "        [ 0.6172,  0.3593, -0.7287, -0.7319],\n",
      "        [-0.3811,  0.1250, -0.6905,  0.8172]], requires_grad=True)\n",
      "Step: 2999 ||WeightFunction-I|| Error: tensor(2.8921e-12, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00,  4.7125e-07, -2.4438e-06,  2.3842e-07],\n",
      "        [-9.5926e-08,  1.0000e+00, -7.4506e-07, -8.9407e-07],\n",
      "        [-2.6822e-07, -2.3097e-06,  1.0000e+00,  6.8545e-07],\n",
      "        [ 6.8545e-07, -6.2585e-07, -2.3842e-07,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "Step: 3999 ||WeightFunction-I|| Error: tensor(1.3993e-12, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00,  1.7881e-07, -1.0729e-06, -8.9407e-08],\n",
      "        [-1.8068e-07,  1.0000e+00, -5.3644e-07, -5.9605e-07],\n",
      "        [-3.2783e-07, -1.4305e-06,  1.0000e+00,  5.6624e-07],\n",
      "        [ 8.0466e-07, -3.1292e-07, -5.9605e-08,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "Step: 4999 ||WeightFunction-I|| Error: tensor(5.7431e-13, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00,  6.8918e-08, -4.1723e-07, -5.9605e-08],\n",
      "        [-6.7055e-08,  1.0000e+00, -3.8743e-07, -3.8743e-07],\n",
      "        [-3.8743e-07, -7.5996e-07,  1.0000e+00,  2.2352e-07],\n",
      "        [ 4.7684e-07, -2.0862e-07, -8.9407e-08,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "Step: 5999 ||WeightFunction-I|| Error: tensor(2.1206e-13, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00, -4.0978e-08, -1.1921e-07, -1.4901e-07],\n",
      "        [-6.3330e-08,  1.0000e+00, -2.3842e-07, -2.5332e-07],\n",
      "        [-2.3842e-07, -4.1723e-07,  1.0000e+00,  1.9372e-07],\n",
      "        [ 3.2783e-07, -1.3411e-07, -8.9407e-08,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "Step: 6999 ||WeightFunction-I|| Error: tensor(7.2876e-14, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00, -4.6566e-08,  0.0000e+00, -8.9407e-08],\n",
      "        [-3.1665e-08,  1.0000e+00, -1.1921e-07, -1.3411e-07],\n",
      "        [-1.9372e-07, -1.6391e-07,  1.0000e+00,  1.4901e-08],\n",
      "        [ 2.0862e-07, -4.4703e-08, -1.1921e-07,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "Step: 7999 ||WeightFunction-I|| Error: tensor(2.7640e-14, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00,  9.3132e-09,  0.0000e+00, -2.9802e-08],\n",
      "        [ 1.6764e-08,  1.0000e+00, -5.9605e-08, -7.4506e-08],\n",
      "        [-1.4901e-07, -1.1921e-07,  1.0000e+00,  5.9605e-08],\n",
      "        [ 1.1921e-07, -1.4901e-08, -2.9802e-08,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "Step: 8999 ||WeightFunction-I|| Error: tensor(1.2753e-14, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00,  1.3039e-08,  0.0000e+00, -2.9802e-08],\n",
      "        [-6.5193e-09,  1.0000e+00, -2.9802e-08, -4.4703e-08],\n",
      "        [-5.9605e-08, -5.9605e-08,  1.0000e+00,  2.9802e-08],\n",
      "        [ 5.9605e-08, -1.4901e-08, -5.9605e-08,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "Step: 9999 ||WeightFunction-I|| Error: tensor(5.1098e-15, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.0000e+00, -5.5879e-09,  0.0000e+00,  0.0000e+00],\n",
      "        [-3.7253e-09,  1.0000e+00,  0.0000e+00, -1.4901e-08],\n",
      "        [-4.4703e-08, -2.9802e-08,  1.0000e+00,  1.4901e-08],\n",
      "        [ 5.9605e-08, -1.4901e-08,  0.0000e+00,  1.0000e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Parameter containing:\n",
      "tensor([[ 0.8140, -0.1410,  0.4275, -0.0252],\n",
      "        [-0.0055,  1.0410,  0.2164,  0.2394],\n",
      "        [ 0.1649,  0.3359, -0.5788, -0.5861],\n",
      "        [ 0.5197,  0.0581, -0.3228,  0.6799]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.8862, -0.0366,  0.4156,  0.4039],\n",
      "        [-0.0361,  0.8567,  0.3125, -0.0336],\n",
      "        [ 0.6175,  0.3597, -0.7288, -0.7320],\n",
      "        [-0.3811,  0.1256, -0.6904,  0.8173]], requires_grad=True)\n",
      "tensor([[-0.4372,  0.5277, -1.3428, -1.2079]])\n",
      "tensor([[-0.4372,  0.5277, -1.3428, -1.2079]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "class NetworkModel(nn.Module):\n",
    "\n",
    "    def __init__(self, inputDim):\n",
    "\n",
    "        # Initialize the network layers.\n",
    "\n",
    "        super(NetworkModel, self).__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(inputDim, inputDim, bias=False)\n",
    "        self.lin2 = nn.Linear(inputDim, inputDim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # A forward function\n",
    "        # Linear function without activation\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "#         Vin -> V1 -> Vout\n",
    "#         V1 = Vin * W1'\n",
    "#         Vout = V1 * W2' \n",
    "#             = Vin * W1' * W2'\n",
    "\n",
    "        return x\n",
    "\n",
    "class TrainModel():\n",
    "\n",
    "    def __init__(self, model, device, learningRate, inputDim, batchSize, numberOfSteps):\n",
    "\n",
    "        self.device = device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=learningRate)\n",
    "        self.inputDim = inputDim\n",
    "        self.batchSize = batchSize\n",
    "        self.numberOfSteps = numberOfSteps\n",
    "\n",
    "    def train(self,):\n",
    "\n",
    "        for step in range(self.numberOfSteps):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            input = torch.randn((self.batchSize, self.inputDim)).to(self.device)\n",
    "            output = self.net(input)\n",
    "            loss = F.mse_loss(input, output)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            weight_dict = OrderedDict(self.net.named_parameters())\n",
    "            weightFunction = weight_dict['lin1.weight'].T @ weight_dict['lin2.weight'].T\n",
    "            identityMatrix = torch.eye(self.inputDim).to(self.device)\n",
    "            error = F.mse_loss(weightFunction, identityMatrix)\n",
    "            if((step+1)%1000==0):\n",
    "                print(\"Step: \" + str(step) + \" ||WeightFunction-I|| Error: \" + str(error))\n",
    "                print(weightFunction, 6)\n",
    "#                 print(torch.round(weightFunction), 6)\n",
    "                print(weight_dict['lin1.weight'])\n",
    "                print(weight_dict['lin2.weight'])\n",
    "        \n",
    "\n",
    "    def test(self,n):\n",
    "\n",
    "        test_samples = torch.randn(n, self.inputDim).to(self.device)\n",
    "        preds = self.net(test_samples)\n",
    "        print(test_samples)\n",
    "        print(preds)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Please change the inputs here\n",
    "    inputDim = 4\n",
    "\n",
    "    # Additional inputs may not be required to change.\n",
    "    learningRate = 0.0005\n",
    "    batchSize = 64\n",
    "    numberOfSteps = 10000\n",
    "\n",
    "    # Additional Initializer\n",
    "    device = torch.device('cpu')\n",
    "    model =  NetworkModel(inputDim)\n",
    "    trainer = TrainModel(model, device, learningRate, inputDim, batchSize, numberOfSteps)\n",
    "    trainer.train()\n",
    "    trainer.test(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ajPPna9rQtZJ",
    "outputId": "325efbd2-b733-4f2d-8527-f6419a37f71c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 ||WeightFunction-I|| Error: tensor(0.3352, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.1423,  0.1059,  0.0789, -0.0142],\n",
      "        [-0.0827,  0.0473, -0.2936,  0.2561],\n",
      "        [-0.4200,  0.1677, -0.1813,  0.1069],\n",
      "        [ 0.0613, -0.0089,  0.1973, -0.1490]], grad_fn=<MmBackward0>) 6\n",
      "Step: 5000 ||WeightFunction-I|| Error: tensor(0.0570, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4308, -0.0270,  0.1435, -0.0122],\n",
      "        [-0.0226,  1.4455,  0.1530, -0.0431],\n",
      "        [ 0.1463,  0.1410,  0.5654,  0.1368],\n",
      "        [-0.0223, -0.0154,  0.1563,  1.4539]], grad_fn=<MmBackward0>) 6\n",
      "Step: 10000 ||WeightFunction-I|| Error: tensor(0.0555, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4452, -0.0192,  0.1339, -0.0374],\n",
      "        [-0.0303,  1.4520,  0.1286, -0.0294],\n",
      "        [ 0.1397,  0.1213,  0.5807,  0.1681],\n",
      "        [-0.0275, -0.0143,  0.1676,  1.4251]], grad_fn=<MmBackward0>) 6\n",
      "Step: 15000 ||WeightFunction-I|| Error: tensor(0.0585, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4429, -0.0169,  0.1698, -0.0302],\n",
      "        [-0.0234,  1.4546,  0.1318, -0.0250],\n",
      "        [ 0.1638,  0.1322,  0.5704,  0.1610],\n",
      "        [-0.0295, -0.0255,  0.1713,  1.4455]], grad_fn=<MmBackward0>) 6\n",
      "Step: 20000 ||WeightFunction-I|| Error: tensor(0.0577, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4366, -0.0261,  0.1624, -0.0161],\n",
      "        [-0.0210,  1.4574,  0.1204, -0.0238],\n",
      "        [ 0.1607,  0.1152,  0.5633,  0.1648],\n",
      "        [-0.0256, -0.0201,  0.1676,  1.4401]], grad_fn=<MmBackward0>) 6\n",
      "Step: 25000 ||WeightFunction-I|| Error: tensor(0.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4461, -0.0188,  0.1413, -0.0313],\n",
      "        [-0.0184,  1.4534,  0.1167, -0.0114],\n",
      "        [ 0.1444,  0.1160,  0.5616,  0.1675],\n",
      "        [-0.0086, -0.0212,  0.1609,  1.4356]], grad_fn=<MmBackward0>) 6\n",
      "Step: 30000 ||WeightFunction-I|| Error: tensor(0.0597, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4592, -0.0150,  0.1414, -0.0338],\n",
      "        [-0.0288,  1.4729,  0.1327, -0.0079],\n",
      "        [ 0.1448,  0.1290,  0.5518,  0.1662],\n",
      "        [-0.0251, -0.0254,  0.1537,  1.4355]], grad_fn=<MmBackward0>) 6\n",
      "Step: 35000 ||WeightFunction-I|| Error: tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4555, -0.0207,  0.1452, -0.0235],\n",
      "        [-0.0108,  1.4594,  0.1183, -0.0211],\n",
      "        [ 0.1293,  0.1341,  0.5544,  0.1665],\n",
      "        [-0.0207, -0.0331,  0.1728,  1.4282]], grad_fn=<MmBackward0>) 6\n",
      "Step: 40000 ||WeightFunction-I|| Error: tensor(0.0639, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4804, -0.0155,  0.1295, -0.0056],\n",
      "        [-0.0088,  1.4750,  0.1386, -0.0198],\n",
      "        [ 0.1148,  0.1153,  0.5247,  0.1883],\n",
      "        [-0.0207, -0.0195,  0.1872,  1.4531]], grad_fn=<MmBackward0>) 6\n",
      "Step: 45000 ||WeightFunction-I|| Error: tensor(0.0560, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4567, -0.0199,  0.1192, -0.0111],\n",
      "        [-0.0198,  1.4485,  0.1273, -0.0264],\n",
      "        [ 0.1099,  0.1206,  0.5772,  0.1776],\n",
      "        [-0.0174, -0.0236,  0.1729,  1.4312]], grad_fn=<MmBackward0>) 6\n",
      "Step: 50000 ||WeightFunction-I|| Error: tensor(0.0582, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4682, -0.0095,  0.0995, -0.0295],\n",
      "        [-0.0070,  1.4625,  0.1270, -0.0279],\n",
      "        [ 0.0956,  0.1255,  0.5578,  0.1659],\n",
      "        [-0.0315, -0.0325,  0.1825,  1.4332]], grad_fn=<MmBackward0>) 6\n",
      "Step: 55000 ||WeightFunction-I|| Error: tensor(0.0591, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4663, -0.0202,  0.1023, -0.0269],\n",
      "        [-0.0160,  1.4516,  0.1361, -0.0206],\n",
      "        [ 0.1107,  0.1301,  0.5562,  0.1812],\n",
      "        [-0.0280, -0.0217,  0.1705,  1.4520]], grad_fn=<MmBackward0>) 6\n",
      "Step: 60000 ||WeightFunction-I|| Error: tensor(0.0592, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4554, -0.0210,  0.0933, -0.0341],\n",
      "        [-0.0099,  1.4617,  0.1394, -0.0149],\n",
      "        [ 0.0885,  0.1311,  0.5358,  0.1628],\n",
      "        [-0.0282, -0.0302,  0.1665,  1.4469]], grad_fn=<MmBackward0>) 6\n",
      "Step: 65000 ||WeightFunction-I|| Error: tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4574e+00, -6.8751e-03,  5.0137e-02, -9.8855e-03],\n",
      "        [-2.7102e-04,  1.4571e+00,  1.4466e-01, -3.3868e-02],\n",
      "        [ 6.0781e-02,  1.4174e-01,  5.4715e-01,  1.6621e-01],\n",
      "        [-2.2042e-02, -2.8105e-02,  1.5957e-01,  1.4418e+00]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Step: 70000 ||WeightFunction-I|| Error: tensor(0.0576, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4833, -0.0061,  0.0566, -0.0020],\n",
      "        [-0.0127,  1.4387,  0.1599, -0.0290],\n",
      "        [ 0.0488,  0.1639,  0.5377,  0.1148],\n",
      "        [-0.0105, -0.0264,  0.1367,  1.4360]], grad_fn=<MmBackward0>) 6\n",
      "Step: 75000 ||WeightFunction-I|| Error: tensor(0.0567, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4613, -0.0151,  0.0775, -0.0102],\n",
      "        [-0.0099,  1.4330,  0.1820, -0.0189],\n",
      "        [ 0.0847,  0.1776,  0.5552,  0.1129],\n",
      "        [-0.0158, -0.0077,  0.1113,  1.4533]], grad_fn=<MmBackward0>) 6\n",
      "Step: 80000 ||WeightFunction-I|| Error: tensor(0.0611, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4921, -0.0148,  0.0683, -0.0050],\n",
      "        [-0.0075,  1.4436,  0.1832, -0.0349],\n",
      "        [ 0.0738,  0.1727,  0.5398,  0.1417],\n",
      "        [-0.0100, -0.0406,  0.1396,  1.4580]], grad_fn=<MmBackward0>) 6\n",
      "Step: 85000 ||WeightFunction-I|| Error: tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4761, -0.0229,  0.0714, -0.0081],\n",
      "        [-0.0156,  1.4472,  0.1591, -0.0128],\n",
      "        [ 0.1020,  0.1614,  0.5435,  0.1081],\n",
      "        [-0.0027, -0.0112,  0.1135,  1.4484]], grad_fn=<MmBackward0>) 6\n",
      "Step: 90000 ||WeightFunction-I|| Error: tensor(0.0580, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4728, -0.0183,  0.1072, -0.0193],\n",
      "        [-0.0234,  1.4467,  0.1350, -0.0164],\n",
      "        [ 0.1020,  0.1276,  0.5388,  0.1065],\n",
      "        [-0.0161, -0.0194,  0.1097,  1.4583]], grad_fn=<MmBackward0>) 6\n",
      "Step: 95000 ||WeightFunction-I|| Error: tensor(0.0596, grad_fn=<MseLossBackward0>)\n",
      "tensor([[ 1.4638, -0.0027,  0.0586, -0.0193],\n",
      "        [-0.0111,  1.4538,  0.1453, -0.0220],\n",
      "        [ 0.0704,  0.1460,  0.5268,  0.1396],\n",
      "        [-0.0085, -0.0178,  0.1416,  1.4658]], grad_fn=<MmBackward0>) 6\n",
      "tensor([[-0.4730,  1.7162, -1.6848,  0.5825]])\n",
      "tensor([[-0.8732,  2.2333, -0.6364,  0.5363]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "class NetworkModel(nn.Module):\n",
    "\n",
    "    def __init__(self, inputDim):\n",
    "\n",
    "        # Initialize the network layers.\n",
    "\n",
    "        super(NetworkModel, self).__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(inputDim, inputDim, bias=False)\n",
    "        self.lin2 = nn.Linear(inputDim, inputDim, bias=False)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # A forward function\n",
    "        # Linear function with activation\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class TrainModel():\n",
    "\n",
    "    def __init__(self, model, device, learningRate, inputDim, batchSize, numberOfSteps):\n",
    "\n",
    "        self.device = device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=learningRate)\n",
    "        self.inputDim = inputDim\n",
    "        self.batchSize = batchSize\n",
    "        self.numberOfSteps = numberOfSteps\n",
    "\n",
    "    def train(self,):\n",
    "\n",
    "        for step in range(self.numberOfSteps):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            input = torch.randn((self.batchSize, self.inputDim)).to(self.device)\n",
    "            output = self.net(input)\n",
    "            loss = F.mse_loss(input, output)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            weight_dict = OrderedDict(self.net.named_parameters())\n",
    "            weightFunction = weight_dict['lin1.weight'].T @ weight_dict['lin2.weight'].T\n",
    "            identityMatrix = torch.eye(self.inputDim).to(self.device)\n",
    "            error = F.mse_loss(weightFunction, identityMatrix)\n",
    "            if(step%5000==0):\n",
    "                print(\"Step: \" + str(step) + \" ||WeightFunction-I|| Error: \" + str(error))\n",
    "                print(weightFunction, 6)\n",
    "\n",
    "#         print(torch.round(weightFunction), 6)\n",
    "\n",
    "    def test(self,n):\n",
    "\n",
    "        test_samples = torch.randn(n, self.inputDim).to(self.device)\n",
    "        preds = self.net(test_samples)\n",
    "        print(test_samples)\n",
    "        print(preds)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Please change the inputs here\n",
    "    inputDim = 4\n",
    "\n",
    "    # Additional inputs may not be required to change.\n",
    "    learningRate = 0.0005\n",
    "    batchSize = 64\n",
    "    numberOfSteps = 100000\n",
    "\n",
    "    # Additional Initializer\n",
    "    device = torch.device('cpu')\n",
    "    model =  NetworkModel(inputDim)\n",
    "    trainer = TrainModel(model, device, learningRate, inputDim, batchSize, numberOfSteps)\n",
    "    trainer.train()\n",
    "    trainer.test(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning with single layer neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 ||WeightFunction-I|| Error: tensor(0.3683, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0088, -0.0940, -0.0361, -0.4316],\n",
      "        [-0.3889, -0.3898, -0.3222, -0.3349],\n",
      "        [ 0.1227,  0.3530, -0.2808, -0.1061],\n",
      "        [-0.1524, -0.2852, -0.0176,  0.3043]], grad_fn=<PermuteBackward0>)\n",
      "Step: 1000 ||WeightFunction-I|| Error: tensor(0.3697, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0115, -0.0900, -0.0317, -0.4270],\n",
      "        [-0.3937, -0.3935, -0.3175, -0.3302],\n",
      "        [ 0.1188,  0.3482, -0.2851, -0.1106],\n",
      "        [-0.1571, -0.2805, -0.0222,  0.2997]], grad_fn=<PermuteBackward0>)\n",
      "Step: 2000 ||WeightFunction-I|| Error: tensor(0.3711, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0141, -0.0861, -0.0274, -0.4226],\n",
      "        [-0.3985, -0.3972, -0.3129, -0.3257],\n",
      "        [ 0.1150,  0.3435, -0.2895, -0.1151],\n",
      "        [-0.1619, -0.2758, -0.0267,  0.2951]], grad_fn=<PermuteBackward0>)\n",
      "Step: 3000 ||WeightFunction-I|| Error: tensor(0.3725, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0169, -0.0821, -0.0229, -0.4181],\n",
      "        [-0.4032, -0.4007, -0.3083, -0.3211],\n",
      "        [ 0.1114,  0.3388, -0.2941, -0.1195],\n",
      "        [-0.1667, -0.2711, -0.0313,  0.2906]], grad_fn=<PermuteBackward0>)\n",
      "Step: 4000 ||WeightFunction-I|| Error: tensor(0.3741, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0198, -0.0780, -0.0186, -0.4135],\n",
      "        [-0.4080, -0.4045, -0.3037, -0.3166],\n",
      "        [ 0.1078,  0.3342, -0.2986, -0.1240],\n",
      "        [-0.1714, -0.2665, -0.0358,  0.2861]], grad_fn=<PermuteBackward0>)\n",
      "Step: 5000 ||WeightFunction-I|| Error: tensor(0.3757, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0227, -0.0741, -0.0143, -0.4091],\n",
      "        [-0.4127, -0.4082, -0.2991, -0.3121],\n",
      "        [ 0.1044,  0.3295, -0.3031, -0.1285],\n",
      "        [-0.1761, -0.2618, -0.0403,  0.2815]], grad_fn=<PermuteBackward0>)\n",
      "Step: 6000 ||WeightFunction-I|| Error: tensor(0.3773, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0257, -0.0705, -0.0100, -0.4046],\n",
      "        [-0.4174, -0.4119, -0.2945, -0.3075],\n",
      "        [ 0.1011,  0.3248, -0.3077, -0.1329],\n",
      "        [-0.1808, -0.2572, -0.0449,  0.2769]], grad_fn=<PermuteBackward0>)\n",
      "Step: 7000 ||WeightFunction-I|| Error: tensor(0.3790, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0289, -0.0667, -0.0055, -0.4001],\n",
      "        [-0.4222, -0.4157, -0.2899, -0.3030],\n",
      "        [ 0.0980,  0.3202, -0.3123, -0.1374],\n",
      "        [-0.1855, -0.2526, -0.0493,  0.2724]], grad_fn=<PermuteBackward0>)\n",
      "Step: 8000 ||WeightFunction-I|| Error: tensor(0.3808, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0322, -0.0629, -0.0012, -0.3956],\n",
      "        [-0.4269, -0.4197, -0.2853, -0.2985],\n",
      "        [ 0.0946,  0.3156, -0.3169, -0.1418],\n",
      "        [-0.1903, -0.2480, -0.0538,  0.2679]], grad_fn=<PermuteBackward0>)\n",
      "Step: 9000 ||WeightFunction-I|| Error: tensor(0.3827, grad_fn=<MseLossBackward0>)\n",
      "tensor([[-0.0355, -0.0593,  0.0031, -0.3911],\n",
      "        [-0.4316, -0.4235, -0.2807, -0.2940],\n",
      "        [ 0.0916,  0.3109, -0.3216, -0.1463],\n",
      "        [-0.1950, -0.2433, -0.0584,  0.2633]], grad_fn=<PermuteBackward0>)\n",
      "tensor([[ 0.0079, -1.0670,  0.4527, -0.3588]])\n",
      "tensor([[ 0.1064, -0.5815, -0.3829, -0.0136]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NetworkModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputDim):\n",
    "        \n",
    "        super(NetworkModel, self).__init__()\n",
    "        self.lin = nn.Linear(inputDim, inputDim, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "    \n",
    "class TrainModel():\n",
    "    \n",
    "    def __init__(self, model, device, learningRate, inputDim, batchSize, numberOfSteps):\n",
    "        \n",
    "        self.device = device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=learningRate)\n",
    "        self.inputDim = inputDim\n",
    "        self.batchSize = batchSize\n",
    "        self.numberOfSteps = numberOfSteps\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        for step in range(self.numberOfSteps):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            input = torch.randn((self.batchSize, self.inputDim)).to(self.device)\n",
    "            output = self.net(input)\n",
    "            loss = F.mse_loss(input, output)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            weight_dict = OrderedDict(self.net.named_parameters())\n",
    "            weightFunction = weight_dict['lin1.weight'].T\n",
    "            identityMatrix = torch.eye(self.inputDim).to(self.device)\n",
    "            error = F.mse_loss(weightFunction, identityMatrix)\n",
    "            if(step%1000==0):\n",
    "                print(\"Step: \" + str(step) + \" ||WeightFunction-I|| Error: \" + str(error))\n",
    "                print(weightFunction)\n",
    "        \n",
    "    def test(self,n):\n",
    "\n",
    "        test_samples = torch.randn(n, self.inputDim).to(self.device)\n",
    "        preds = self.net(test_samples)\n",
    "        print(test_samples)\n",
    "        print(preds)\n",
    "        \n",
    "def main():\n",
    "        \n",
    "    inputDim = 4\n",
    "\n",
    "    learningRate = 0.000005\n",
    "    batchSize = 64\n",
    "    numberOfSteps = 10000\n",
    "\n",
    "    # Additional Initializer\n",
    "    device = torch.device('cpu')\n",
    "    model =  NetworkModel(inputDim)\n",
    "    trainer = TrainModel(model, device, learningRate, inputDim, batchSize, numberOfSteps)\n",
    "    trainer.train()\n",
    "    trainer.test(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main() \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
