{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6182a22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation of input numbers i.e. truth tables: \n",
      " tensor([ 16,  35, 154,  14, 151, 114,  44,  22, 174, 163,  25,  38, 141, 207,\n",
      "        139, 133,  48,  17, 119, 109, 108,  73, 175,  13,   3,  64, 210, 111,\n",
      "        245, 204,  47,  97,  80, 104, 103,  59,  29, 202,  78, 181, 194,  39,\n",
      "          6, 209, 117, 200, 226,  15, 125, 250,  71, 233,   4, 172,  92, 254,\n",
      "         24, 167, 252, 227,  83,  82, 186, 105, 196, 102,  27,  52, 182, 230,\n",
      "        120, 149, 253,  90,  88, 247, 240, 123, 248, 169, 246, 147, 164, 220,\n",
      "        122,   9, 170, 101,  31, 191,   1,  54, 242, 127, 110, 173,  98, 217,\n",
      "        143, 219,  95, 165,  18,   5, 100, 144, 145,  21, 212, 234,  96, 159,\n",
      "         62, 135,   7,  66, 215,  74, 129,  89, 238,  41,  55,  40,  63, 201,\n",
      "        211, 197, 205, 185,  57, 228, 192, 157, 229,  76, 178, 249, 136, 112,\n",
      "        134, 224, 222, 221, 124,  68,  30,  84, 225, 128, 216, 255,  32, 150,\n",
      "          0, 138,  49, 251,  93,  53,  91,  36,  87, 214, 160,  33, 126, 199,\n",
      "        166,  50,  75, 190, 140,  46, 142,  43,  70,  45,  37, 244,  67, 177,\n",
      "        208, 162, 176, 168,  60,  56, 198, 158, 148, 115, 203,  81,  51, 218,\n",
      "        137, 231, 241,  65,  72, 195, 187, 153, 156,  61, 132, 179, 113, 243,\n",
      "         26, 232, 121, 184, 161, 188, 106, 180, 189,  28, 235,  99, 206, 183,\n",
      "         42, 130, 236,  77, 223, 107,  20,  10,  58, 239, 237, 131, 146,  23,\n",
      "        116,  94,  12,  34,   2, 193, 155,  86,  19,  11, 213, 171,   8,  79,\n",
      "         69, 152,  85, 118])\n",
      "Binary version of permutation: \n",
      " [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0], [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0], [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0], [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0], [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]]\n",
      "ep=  0 \n",
      " tensor([[ 0.5034,  0.2006, -0.0233,  0.3509,  0.1535, -0.2685,  0.0731,  0.0473],\n",
      "        [ 0.5607, -0.1093,  0.3620, -0.1624,  0.1143, -0.4144,  0.0682, -0.2224],\n",
      "        [ 0.9260, -0.0400, -0.1047, -0.1853, -0.3743,  0.3914, -0.1581, -0.2883],\n",
      "        [ 0.0389, -0.0475,  0.0543,  0.4088,  0.5435, -0.3801,  0.0684, -0.0059],\n",
      "        [ 0.5823, -0.0198,  0.0757, -0.1287, -0.0757, -0.1290, -0.0622, -0.1666],\n",
      "        [ 1.2646, -0.1070,  0.0401, -0.6763, -0.6554,  0.4660, -0.1491, -0.3189],\n",
      "        [ 0.6977,  0.2772, -0.0901, -0.3731, -0.2747, -0.1337, -0.0162,  0.0208],\n",
      "        [ 0.7949, -0.1382, -0.1538, -0.0887, -0.3090,  0.5744, -0.1468, -0.1960]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  1 \n",
      " tensor([[ 0.8476,  0.2526,  0.0627,  0.6454,  0.4304, -0.3650,  0.3856,  0.2270],\n",
      "        [ 0.9161, -0.2715,  0.6724, -0.2460,  0.4862, -0.7949,  0.2276, -0.2918],\n",
      "        [ 1.1446, -0.1098, -0.2694, -0.2344, -0.3542,  0.4752, -0.2239, -0.3436],\n",
      "        [ 0.4586, -0.1908, -0.0919,  0.7417,  0.9162, -0.4744,  0.1417,  0.0566],\n",
      "        [ 0.8906, -0.0402,  0.2226, -0.0903,  0.0631, -0.2757,  0.0361, -0.1964],\n",
      "        [ 1.3730, -0.2759,  0.0211, -0.7999, -0.8624,  0.6524, -0.1997, -0.3253],\n",
      "        [ 0.9326,  0.5681, -0.1525, -0.4487, -0.3512, -0.2669,  0.1856,  0.2972],\n",
      "        [ 0.9843, -0.3598, -0.3325,  0.0939, -0.3511,  0.8394, -0.2114, -0.2311]],\n",
      "       grad_fn=<MmBackward0>) 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep=  2 \n",
      " tensor([[ 0.9826,  0.3916,  0.1983,  0.9183,  0.4126, -0.2266,  0.7104,  0.5025],\n",
      "        [ 1.0529, -0.4001,  0.9671, -0.4911,  0.7325, -1.0108,  0.2156, -0.5228],\n",
      "        [ 1.0883, -0.1010, -0.5090, -0.3681, -0.2811,  0.4225, -0.4449, -0.5169],\n",
      "        [ 0.7439, -0.4108, -0.4234,  0.9467,  1.1508, -0.3916,  0.0740,  0.1272],\n",
      "        [ 0.9452,  0.0488,  0.4103, -0.1128,  0.0304, -0.3080,  0.0459, -0.2836],\n",
      "        [ 1.1426, -0.3265,  0.1093, -0.8377, -1.0666,  0.7178, -0.2788, -0.3616],\n",
      "        [ 0.9099,  0.9987, -0.1960, -0.5823, -0.5601, -0.3576,  0.4080,  0.6300],\n",
      "        [ 0.9666, -0.5424, -0.4959,  0.3660, -0.3717,  1.0287, -0.2887, -0.2276]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  3 \n",
      " tensor([[ 1.0229,  0.4903,  0.4345,  1.1956,  0.2284, -0.0226,  1.0104,  0.7570],\n",
      "        [ 1.0583, -0.4924,  1.1220, -0.7175,  0.9388, -1.0973,  0.1576, -0.7722],\n",
      "        [ 1.0577, -0.0408, -0.8637, -0.6095, -0.0235,  0.2713, -0.6596, -0.7276],\n",
      "        [ 0.8679, -0.6331, -0.8419,  0.9431,  1.2877, -0.3738, -0.0389,  0.2342],\n",
      "        [ 0.9598,  0.1966,  0.6431, -0.0433, -0.1129, -0.2644,  0.0227, -0.4071],\n",
      "        [ 1.0159, -0.3957,  0.2786, -0.7512, -1.2103,  0.7432, -0.2627, -0.3178],\n",
      "        [ 0.9238,  1.2942, -0.2963, -0.7256, -0.6909, -0.4323,  0.5777,  0.9163],\n",
      "        [ 1.0024, -0.6962, -0.5578,  0.6170, -0.4172,  1.1503, -0.2671, -0.1457]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  4 \n",
      " tensor([[ 1.0258,  0.5135,  0.6250,  1.3411,  0.1492,  0.0669,  1.1414,  0.8082],\n",
      "        [ 1.0309, -0.5400,  1.1806, -0.8224,  1.0697, -1.0682,  0.1972, -0.8545],\n",
      "        [ 1.0426,  0.1285, -1.1691, -0.8241,  0.2254,  0.2221, -0.7341, -0.8784],\n",
      "        [ 0.9027, -0.7945, -1.1218,  0.8356,  1.3196, -0.4283, -0.0901,  0.3926],\n",
      "        [ 0.9693,  0.3832,  0.8668,  0.1562, -0.3034, -0.2370, -0.0809, -0.5677],\n",
      "        [ 0.9563, -0.5198,  0.4502, -0.6352, -1.3523,  0.7460, -0.2362, -0.2152],\n",
      "        [ 0.9615,  1.3652, -0.5058, -0.9109, -0.6623, -0.5155,  0.6169,  1.0747],\n",
      "        [ 1.0470, -0.7835, -0.4987,  0.7836, -0.5129,  1.2217, -0.2089, -0.0823]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  5 \n",
      " tensor([[ 1.0092,  0.5593,  0.6608,  1.3209,  0.2228,  0.1196,  1.1973,  0.7409],\n",
      "        [ 1.0210, -0.6129,  1.2188, -0.8770,  1.1319, -0.9829,  0.3047, -0.8145],\n",
      "        [ 1.0293,  0.3336, -1.2821, -0.8958,  0.3786,  0.2957, -0.7017, -1.0184],\n",
      "        [ 0.9127, -0.9234, -1.1893,  0.8008,  1.2468, -0.5147, -0.1366,  0.5316],\n",
      "        [ 0.9828,  0.5934,  0.9841,  0.3926, -0.4792, -0.3089, -0.2798, -0.7380],\n",
      "        [ 0.9234, -0.7005,  0.5308, -0.6153, -1.4435,  0.6913, -0.2343, -0.0697],\n",
      "        [ 0.9904,  1.3147, -0.6735, -1.0569, -0.6105, -0.5593,  0.6387,  1.1893],\n",
      "        [ 1.0785, -0.8125, -0.4571,  0.8525, -0.5574,  1.2547, -0.1666, -0.0908]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  6 \n",
      " tensor([[ 0.9827,  0.6390,  0.6498,  1.2491,  0.3472,  0.2350,  1.2860,  0.6589],\n",
      "        [ 1.0259, -0.7096,  1.2387, -0.9448,  1.1761, -0.8965,  0.4130, -0.7485],\n",
      "        [ 1.0073,  0.5297, -1.2965, -0.8964,  0.4877,  0.4092, -0.6482, -1.1758],\n",
      "        [ 0.9255, -1.0081, -1.1737,  0.8513,  1.1270, -0.6607, -0.2535,  0.6223],\n",
      "        [ 0.9967,  0.7829,  1.0159,  0.6209, -0.6392, -0.4760, -0.5162, -0.8678],\n",
      "        [ 0.9053, -0.9037,  0.5577, -0.6838, -1.4834,  0.6256, -0.2385,  0.1018],\n",
      "        [ 1.0135,  1.2370, -0.7339, -1.1140, -0.6112, -0.5801,  0.6603,  1.2729],\n",
      "        [ 1.0970, -0.7990, -0.4716,  0.8661, -0.5486,  1.2963, -0.1093, -0.1405]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  7 \n",
      " tensor([[ 0.9543,  0.7164,  0.6562,  1.1777,  0.4719,  0.3963,  1.3955,  0.5951],\n",
      "        [ 1.0375, -0.7895,  1.2390, -1.0063,  1.2102, -0.8315,  0.4961, -0.7004],\n",
      "        [ 0.9778,  0.6819, -1.2896, -0.8943,  0.5744,  0.5218, -0.5964, -1.2962],\n",
      "        [ 0.9401, -1.0492, -1.1548,  0.9305,  1.0097, -0.8452, -0.4216,  0.6879],\n",
      "        [ 1.0062,  0.9096,  1.0140,  0.8085, -0.7856, -0.6824, -0.7311, -0.9441],\n",
      "        [ 0.8977, -1.0719,  0.5872, -0.7768, -1.4804,  0.5925, -0.2550,  0.2577],\n",
      "        [ 1.0339,  1.1819, -0.7548, -1.1121, -0.6468, -0.6209,  0.6593,  1.3113],\n",
      "        [ 1.1071, -0.7714, -0.5115,  0.8697, -0.5333,  1.3525, -0.0149, -0.2138]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  8 \n",
      " tensor([[ 0.9341,  0.7725,  0.6890,  1.1186,  0.5828,  0.5517,  1.4700,  0.5778],\n",
      "        [ 1.0485, -0.8368,  1.2219, -1.0378,  1.2220, -0.8021,  0.5568, -0.6886],\n",
      "        [ 0.9515,  0.7706, -1.2652, -0.9073,  0.6437,  0.6181, -0.5667, -1.3469],\n",
      "        [ 0.9497, -1.0679, -1.1340,  0.9866,  0.9325, -0.9940, -0.5836,  0.7489],\n",
      "        [ 1.0072,  0.9706,  1.0018,  0.9270, -0.9019, -0.8556, -0.8775, -0.9835],\n",
      "        [ 0.8966, -1.1646,  0.6391, -0.8577, -1.4307,  0.6112, -0.3055,  0.3890],\n",
      "        [ 1.0481,  1.1507, -0.7827, -1.0841, -0.7038, -0.6896,  0.6542,  1.3074],\n",
      "        [ 1.1109, -0.7551, -0.5741,  0.8856, -0.5527,  1.3809,  0.1158, -0.3147]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  9 \n",
      " tensor([[ 0.9297,  0.8170,  0.7524,  1.0740,  0.6895,  0.6820,  1.4605,  0.6255],\n",
      "        [ 1.0517, -0.8669,  1.1828, -1.0407,  1.1992, -0.8142,  0.6240, -0.7218],\n",
      "        [ 0.9390,  0.8195, -1.2143, -0.9320,  0.7172,  0.7074, -0.5866, -1.3252],\n",
      "        [ 0.9573, -1.0688, -1.0983,  1.0052,  0.9174, -1.0545, -0.7152,  0.8176],\n",
      "        [ 1.0018,  0.9871,  0.9882,  0.9825, -0.9771, -0.9611, -0.9429, -1.0085],\n",
      "        [ 0.9049, -1.1807,  0.7262, -0.9205, -1.3313,  0.6875, -0.4152,  0.5307],\n",
      "        [ 1.0519,  1.1239, -0.8313, -1.0523, -0.7784, -0.7738,  0.6825,  1.2619],\n",
      "        [ 1.1030, -0.7723, -0.6757,  0.9196, -0.6371,  1.3342,  0.2914, -0.4621]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  10 \n",
      " tensor([[ 0.9434,  0.8701,  0.8437,  1.0400,  0.8055,  0.8039,  1.3569,  0.7356],\n",
      "        [ 1.0421, -0.9027,  1.1195, -1.0277,  1.1389, -0.8673,  0.7256, -0.8012],\n",
      "        [ 0.9463,  0.8673, -1.1354, -0.9603,  0.8141,  0.8094, -0.6745, -1.2389],\n",
      "        [ 0.9712, -1.0476, -1.0482,  1.0027,  0.9523, -1.0391, -0.8345,  0.8995],\n",
      "        [ 0.9956,  0.9847,  0.9805,  1.0014, -1.0139, -1.0096, -0.9565, -1.0252],\n",
      "        [ 0.9300, -1.1365,  0.8445, -0.9669, -1.1932,  0.8112, -0.5948,  0.7061],\n",
      "        [ 1.0426,  1.0879, -0.8964, -1.0267, -0.8642, -0.8628,  0.7604,  1.1803],\n",
      "        [ 1.0748, -0.8364, -0.8139,  0.9601, -0.7820,  1.2103,  0.5259, -0.6625]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  11 \n",
      " tensor([[ 0.9677,  0.9298,  0.9312,  1.0167,  0.9102,  0.9103,  1.2077,  0.8624],\n",
      "        [ 1.0235, -0.9470,  1.0541, -1.0128,  1.0673, -0.9352,  0.8468, -0.8967],\n",
      "        [ 0.9677,  0.9269, -1.0554, -0.9840,  0.9155,  0.9143, -0.8095, -1.1246],\n",
      "        [ 0.9889, -1.0163, -1.0090,  0.9975,  0.9925, -1.0038, -0.9389,  0.9701],\n",
      "        [ 0.9938,  0.9843,  0.9852,  1.0040, -1.0187, -1.0182, -0.9621, -1.0252],\n",
      "        [ 0.9643, -1.0667,  0.9477, -0.9942, -1.0694,  0.9314, -0.7962,  0.8725],\n",
      "        [ 1.0255,  1.0481, -0.9549, -1.0106, -0.9383, -0.9377,  0.8598,  1.0938],\n",
      "        [ 1.0361, -0.9230, -0.9348,  0.9895, -0.9204,  1.0775,  0.7718, -0.8562]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  12 \n",
      " tensor([[ 0.9869,  0.9725,  0.9802,  1.0049,  0.9709,  0.9722,  1.0902,  0.9476],\n",
      "        [ 1.0087, -0.9800,  1.0160, -1.0040,  1.0220, -0.9793,  0.9372, -0.9620],\n",
      "        [ 0.9869,  0.9735, -1.0132, -0.9965,  0.9756,  0.9780, -0.9214, -1.0453],\n",
      "        [ 0.9992, -0.9997, -0.9987,  0.9976,  1.0042, -0.9936, -0.9932,  0.9991],\n",
      "        [ 0.9964,  0.9914,  0.9946,  1.0018, -1.0088, -1.0086, -0.9781, -1.0133],\n",
      "        [ 0.9884, -1.0186,  0.9931, -1.0027, -1.0110,  0.9912, -0.9323,  0.9655],\n",
      "        [ 1.0110,  1.0194, -0.9873, -1.0027, -0.9805, -0.9811,  0.9372,  1.0364],\n",
      "        [ 1.0103, -0.9798, -0.9880,  1.0001, -0.9856,  1.0120,  0.9296, -0.9623]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  13 \n",
      " tensor([[ 0.9959,  0.9920,  0.9963,  1.0007,  0.9932,  0.9947,  1.0307,  0.9843],\n",
      "        [ 1.0023, -0.9946,  1.0032, -1.0008,  1.0053, -0.9955,  0.9803, -0.9894],\n",
      "        [ 0.9959,  0.9930, -1.0025, -0.9997,  0.9947,  0.9968, -0.9741, -1.0137],\n",
      "        [ 1.0009, -0.9981, -0.9998,  0.9996,  1.0018, -0.9980, -1.0038,  1.0023],\n",
      "        [ 0.9988,  0.9973,  0.9989,  1.0004, -1.0024, -1.0019, -0.9918, -1.0045],\n",
      "        [ 0.9976, -1.0024,  1.0006, -1.0019, -0.9993,  1.0023, -0.9855,  0.9942],\n",
      "        [ 1.0036,  1.0057, -0.9978, -1.0001, -0.9958, -0.9970,  0.9780,  1.0111],\n",
      "        [ 1.0016, -0.9973, -0.9982,  1.0005, -0.9986,  1.0003,  0.9859, -0.9934]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  14 \n",
      " tensor([[ 0.9990,  0.9982,  0.9994,  0.9999,  0.9988,  0.9996,  1.0086,  0.9960],\n",
      "        [ 1.0005, -0.9989,  1.0006, -1.0001,  1.0011, -0.9992,  0.9949, -0.9975],\n",
      "        [ 0.9989,  0.9984, -1.0004, -1.0001,  0.9991,  1.0000, -0.9922, -1.0038],\n",
      "        [ 1.0004, -0.9994, -1.0001,  1.0001,  1.0002, -1.0001, -1.0023,  1.0011],\n",
      "        [ 0.9997,  0.9994,  0.9998,  1.0001, -1.0005, -1.0003, -0.9977, -1.0012],\n",
      "        [ 0.9997, -0.9999,  1.0003, -1.0004, -0.9994,  1.0011, -0.9983,  0.9995],\n",
      "        [ 1.0009,  1.0013, -0.9997, -0.9998, -0.9995, -1.0002,  0.9937,  1.0029],\n",
      "        [ 1.0001, -0.9998, -0.9996,  0.9999, -0.9997,  1.0002,  0.9981, -0.9992]],\n",
      "       grad_fn=<MmBackward0>) 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep=  15 \n",
      " tensor([[ 0.9998,  0.9997,  0.9999,  0.9999,  0.9998,  1.0001,  1.0021,  0.9991],\n",
      "        [ 1.0001, -0.9998,  1.0001, -1.0000,  1.0003, -0.9998,  0.9989, -0.9995],\n",
      "        [ 0.9997,  0.9997, -1.0001, -1.0001,  0.9999,  1.0003, -0.9979, -1.0010],\n",
      "        [ 1.0001, -0.9999, -1.0000,  1.0001,  0.9999, -1.0002, -1.0008,  1.0004],\n",
      "        [ 0.9999,  0.9999,  1.0000,  1.0000, -1.0001, -1.0000, -0.9994, -1.0003],\n",
      "        [ 1.0000, -0.9999,  1.0000, -1.0000, -0.9999,  1.0002, -1.0001,  1.0001],\n",
      "        [ 1.0002,  1.0002, -0.9999, -0.9999, -1.0000, -1.0002,  0.9984,  1.0007],\n",
      "        [ 1.0000, -1.0000, -0.9999,  0.9999, -0.9999,  1.0002,  0.9999, -1.0000]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  16 \n",
      " tensor([[ 1.0000,  0.9999,  1.0000,  1.0000,  1.0000,  1.0001,  1.0005,  0.9998],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000,  1.0001, -1.0000,  0.9998, -0.9999],\n",
      "        [ 0.9999,  0.9999, -1.0000, -1.0000,  1.0000,  1.0001, -0.9995, -1.0002],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0001, -1.0002,  1.0001],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -0.9999, -1.0001],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0001,  1.0001],\n",
      "        [ 1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0001,  0.9997,  1.0002],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000, -0.9999,  1.0001,  1.0000, -1.0000]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  17 \n",
      " tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0001,  1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -0.9999, -1.0000],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.9999,  1.0000],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  18 \n",
      " tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "ep=  19 \n",
      " tensor([[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000, -1.0000,  1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000],\n",
      "        [ 1.0000,  1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000],\n",
      "        [ 1.0000, -1.0000, -1.0000,  1.0000, -1.0000,  1.0000,  1.0000, -1.0000]],\n",
      "       grad_fn=<MmBackward0>) 6\n",
      "Final rounded weight function: \n",
      " tensor([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1., -1.,  1., -1.,  1., -1.],\n",
      "        [ 1.,  1., -1., -1.,  1.,  1., -1., -1.],\n",
      "        [ 1., -1., -1.,  1.,  1., -1., -1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1., -1., -1., -1., -1.],\n",
      "        [ 1., -1.,  1., -1., -1.,  1., -1.,  1.],\n",
      "        [ 1.,  1., -1., -1., -1., -1.,  1.,  1.],\n",
      "        [ 1., -1., -1.,  1., -1.,  1.,  1., -1.]], grad_fn=<RoundBackward0>)\n",
      "Test:\n",
      "tensor([ 4., -2.,  0., -2., -2.,  0.,  2.,  0.]) \n",
      " tensor([ 4., -2.,  0., -2., -2., -0.,  2.,  0.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 5.,  1.,  1.,  1.,  1.,  1.,  1., -3.]) \n",
      " tensor([ 5.,  1.,  1.,  1.,  1.,  1.,  1., -3.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 1., -1.,  1., -1., -1.,  1., -1.,  1.]) \n",
      " tensor([ 1., -1.,  1., -1., -1.,  1., -1.,  1.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 4.,  2.,  2.,  0.,  0.,  2., -2.,  0.]) \n",
      " tensor([ 4.,  2.,  2., -0., -0.,  2., -2., -0.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 4., -2.,  2.,  0.,  0., -2., -2.,  0.]) \n",
      " tensor([ 4., -2.,  2.,  0.,  0., -2., -2.,  0.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 7.,  1.,  1., -1.,  1., -1., -1.,  1.]) \n",
      " tensor([ 7.,  1.,  1., -1.,  1., -1., -1.,  1.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 2.,  0.,  0.,  2.,  0., -2., -2.,  0.]) \n",
      " tensor([ 2., -0.,  0.,  2., -0., -2., -2.,  0.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 5.,  1., -1., -1., -1.,  3.,  1.,  1.]) \n",
      " tensor([ 5.,  1., -1., -1., -1.,  3.,  1.,  1.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 6.,  0.,  2.,  0.,  2.,  0., -2.,  0.]) \n",
      " tensor([ 6., -0.,  2., -0.,  2.,  0., -2., -0.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n",
      "tensor([ 5.,  1., -1., -1.,  1.,  1.,  3., -1.]) \n",
      " tensor([ 5.,  1., -1., -1.,  1.,  1.,  3., -1.], grad_fn=<RoundBackward0>) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "class NetworkModel(nn.Module):\n",
    "\n",
    "    def __init__(self, inputDim):\n",
    "\n",
    "        # Initialize the network layers.\n",
    "\n",
    "        super(NetworkModel, self).__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(inputDim, inputDim, bias=False)\n",
    "        self.lin2 = nn.Linear(inputDim, inputDim, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # A forward function\n",
    "        # Linear function without activation\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "#         F -> temp -> WalshSpec\n",
    "#         temp = F * W1'\n",
    "#         WalshSpec = temp * W2' \n",
    "#             = F * W1' * W2'\n",
    "\n",
    "        return x\n",
    "\n",
    "class TrainModel():\n",
    "\n",
    "    def __init__(self, model, device, learningRate, inputDim, batchSize, numberOfSteps, epochs):\n",
    "\n",
    "        self.device = device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=learningRate)\n",
    "        self.inputDim = inputDim\n",
    "        self.batchSize = batchSize\n",
    "        self.numberOfSteps = numberOfSteps\n",
    "        self.epochs = epochs\n",
    "        self.H = {}\n",
    "        self.H[4] = torch.tensor([[1.0, 1.0, 1.0, 1.0], [1.0, -1.0, 1.0, -1.0], [1.0, 1.0, -1.0, -1.0], [1.0, -1.0, -1.0, 1.0]])\n",
    "        self.H[8] = torch.tensor([[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                            [1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0],\n",
    "                            [1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0],\n",
    "                            [1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0],\n",
    "                            [1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0],\n",
    "                            [1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0],\n",
    "                            [1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0]])\n",
    "        self.perm = torch.randperm(pow(2, self.inputDim))\n",
    "        print(\"Permutation of input numbers i.e. truth tables: \\n\", self.perm)\n",
    "        self.perm = [[0.0]*(self.inputDim-len(bin(num)[2:]))+[float(i) for i in bin(num)[2:]] for num in self.perm]\n",
    "        print(\"Binary version of permutation: \\n\", self.perm)\n",
    "\n",
    "    def train(self,):\n",
    "        \n",
    "        for ep in range(self.epochs):\n",
    "            \n",
    "            for step in range(self.numberOfSteps):\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                input = torch.tensor(self.perm[step])\n",
    "                output = self.net(input)\n",
    "                loss = F.mse_loss(torch.matmul(input, self.H[self.inputDim]), output)\n",
    "    #             print(input, torch.matmul(input, H[self.inputDim]), output)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            weight_dict = OrderedDict(self.net.named_parameters())\n",
    "            weightFunction = weight_dict['lin1.weight'].T @ weight_dict['lin2.weight'].T\n",
    "            print(\"ep= \", ep, \"\\n\", weightFunction, 6)\n",
    "        \n",
    "        weight_dict = OrderedDict(self.net.named_parameters())\n",
    "        weightFunction = weight_dict['lin1.weight'].T @ weight_dict['lin2.weight'].T\n",
    "        print(\"Final rounded weight function: \\n\", torch.round(weightFunction))\n",
    "\n",
    "\n",
    "\n",
    "    def test(self,n):\n",
    "\n",
    "#         test_samples = torch.tensor([[float(el) for el in row] for row in torch.randint(0, 2, (n, self.inputDim)).to(self.device)])\n",
    "        test_samples = torch.tensor(self.perm[self.numberOfSteps:self.numberOfSteps+n])    \n",
    "        preds = self.net(test_samples)\n",
    "        outputs = torch.matmul(test_samples, self.H[self.inputDim])\n",
    "        print(\"Test:\")\n",
    "        for i in range(len(preds)):\n",
    "            print(outputs[i], \"\\n\", torch.round(preds[i]), \"\\n\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Please change the inputs here\n",
    "    inputDim = 8\n",
    "\n",
    "    # Additional inputs may not be required to change.\n",
    "    learningRate = 0.01\n",
    "    batchSize = 1\n",
    "    numberOfSteps = 50\n",
    "    epochs = 20\n",
    "\n",
    "    # Additional Initializer\n",
    "    device = torch.device('cpu')\n",
    "    model =  NetworkModel(inputDim)\n",
    "    trainer = TrainModel(model, device, learningRate, inputDim, batchSize, numberOfSteps, epochs)\n",
    "    trainer.train()\n",
    "    trainer.test(10)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0121be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1, 0], [0, 1, 0, 0], [1, 1, 1, 1], [0, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "print([[0]*(4-len(bin(num)[2:]))+[int(i) for i in bin(num)[2:]] for num in [2, 4, 15, 6]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
