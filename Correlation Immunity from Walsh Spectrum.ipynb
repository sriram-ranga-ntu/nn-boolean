{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df9d292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# random.seed(0)\n",
    "# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e2a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive function to generate Hadamard matrices\n",
    "\n",
    "H = {}\n",
    "H[1] = torch.tensor([[1.0]])\n",
    "def Had(n):\n",
    "    if(n in H):\n",
    "        return H[n]\n",
    "    else:\n",
    "        Hnby2 = Had(n//2)\n",
    "        Hn = torch.ones(n, n)\n",
    "        for i in range(n//2):\n",
    "            for j in range(n//2):\n",
    "                Hn[i][j] = Hnby2[i][j]\n",
    "                Hn[i+n//2][j] = Hnby2[i][j]\n",
    "                Hn[i][j+n//2] = Hnby2[i][j]\n",
    "                Hn[i+n//2][j+n//2] = -Hnby2[i][j]\n",
    "        H[n] = Hn\n",
    "        return Hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02bf8f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated.\n"
     ]
    }
   ],
   "source": [
    "#Generating boolean functions and from them, their walsh spectra to feed as inputs to the neural network\n",
    "\n",
    "#k = number of variables in the boolean functions, n = number of inputs to train the model on\n",
    "def generate_input_data(k, n, scheme='regular'):\n",
    "    two_pow_k, data = pow(2, k), []\n",
    "    if(scheme=='regular'):\n",
    "        if(n<two_pow_k):\n",
    "            print(\"Requested number of inputs less than 2^k. Please request a higher number\")\n",
    "            return data\n",
    "        while(True):\n",
    "            if(two_pow_k<=16):\n",
    "                perm = torch.randperm(pow(2, two_pow_k))\n",
    "                data = [[1.0]*(two_pow_k-len(bin(num)[2:]))+[1.0 if int(i)==0 else -1.0 for i in bin(num)[2:]] for num in perm[:n]]\n",
    "            else:\n",
    "                data = [[1.0 if random.random()>0.5 else -1.0 for i in range(two_pow_k)] for i in range(n)]\n",
    "            rank = np.linalg.matrix_rank(data)\n",
    "            if(rank<two_pow_k):\n",
    "                print(\"Rank (\", rank, \") not large enough, generating data again\")\n",
    "            else:\n",
    "                print(\"Data generated.\")\n",
    "                break\n",
    "    elif(scheme=='one-hot'):\n",
    "        data = [[1.0]*i + [-1.0] + [1.0]*(two_pow_k-i-1) for i in range(two_pow_k)]\n",
    "        print(\"Data generated\")\n",
    "    return torch.tensor(data)\n",
    "\n",
    "k = 3\n",
    "two_pow_k = pow(2, k)\n",
    "if(k<=4):\n",
    "    n = pow(2, two_pow_k)\n",
    "else: \n",
    "    n = k*pow(2, pow(2, 4))\n",
    "boolean_functions = generate_input_data(k, n)\n",
    "walsh_spectra = torch.matmul(boolean_functions, Had(two_pow_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a01a90fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Immunities of functions calculated\n"
     ]
    }
   ],
   "source": [
    "#Calculating the correlation immunity of functions given their walsh spectra\n",
    "\n",
    "def correlation_immunity(walsh_spectra):\n",
    "    ci = []\n",
    "    n, two_pow_k = walsh_spectra.size()[0], walsh_spectra.size()[1]\n",
    "    k = int(math.log2(two_pow_k))\n",
    "    no_ones = []\n",
    "    for i in range(two_pow_k):\n",
    "        no_ones.append(sum([int(dig) for dig in bin(i)[2:]]))\n",
    "    for spectrum in walsh_spectra:\n",
    "        m_ci = [1]*(k+1)\n",
    "        for i in range(two_pow_k):\n",
    "            if(int(spectrum[i])!=0):\n",
    "                m_ci[no_ones[i]] = 0\n",
    "        m = 1\n",
    "        while(m<k+1 and m_ci[m]==1):\n",
    "            m+=1\n",
    "        m -= 1\n",
    "#         # Let ci item = [x0, x1, ..., xm]. x0 is 0 if it is balanced, xi is 1 if it is i-correlation-immune #for unprocessed boolean functions\n",
    "#         ci.append(([1.0] if spectrum[0]==two_pow_k//2 else [0.0])+(m)*[1.0]+(k-m)*[0.0])\n",
    "        # Let ci item = [x0, x1, ..., xm]. x0 is 1 if it is balanced, xi is 1 if it is i-correlation-immune\n",
    "        ci.append(([1.0] if int(spectrum[0])==0 else [0.0])+(m)*[1.0]+(k-m)*[0.0])\n",
    "\n",
    "    return ci\n",
    "\n",
    "ci = torch.tensor(correlation_immunity(walsh_spectra))\n",
    "print(\"Correlation Immunities of functions calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea112288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1., -1., -1., -1., -1.,  1., -1.],\n",
      "        [ 1., -1., -1., -1., -1.,  1., -1., -1.],\n",
      "        [ 1.,  1., -1.,  1., -1.,  1., -1.,  1.],\n",
      "        [ 1., -1.,  1., -1.,  1.,  1.,  1., -1.]])\n",
      "tensor([[-2.,  2.,  2., -2.,  2., -2.,  6.,  2.],\n",
      "        [-4.,  0.,  4.,  0.,  0.,  4.,  0.,  4.],\n",
      "        [ 2., -6.,  2.,  2.,  2.,  2.,  2.,  2.],\n",
      "        [ 2.,  6.,  2., -2., -2.,  2., -2.,  2.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(boolean_functions[:4])\n",
    "print(walsh_spectra[:4])\n",
    "print(ci[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15f2b99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 4])\n",
      "[18, 4, 2]\n",
      "[8, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "ci_count = [0]*k\n",
    "res_count = [0]*k\n",
    "\n",
    "for el in ci: #[:8*32]:\n",
    "    m = 1\n",
    "    while(m<k+1 and el[m]==1):\n",
    "        ci_count[m-1]+=1\n",
    "        if(el[0]==1):\n",
    "            res_count[m-1]+=1\n",
    "        m+=1\n",
    "\n",
    "print(ci.size())\n",
    "print(ci_count)\n",
    "print(res_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a57e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 4])\n",
      "tensor([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ci.size())\n",
    "print(ci[10*5120:(10+1)*5120, 1])\n",
    "\n",
    "327680/5120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d557c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_weights(model_in):\n",
    "    weight_dict = OrderedDict(model_in.named_parameters())\n",
    "    print(weight_dict['lin.weight'])\n",
    "    print(weight_dict['lin.bias'])\n",
    "\n",
    "    print(\"Weights: \", torch.round(weight_dict['lin.weight']))\n",
    "    print(\"Bias: \", torch.round(weight_dict['lin.bias']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f6885d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        two_pow_k = pow(2,k)\n",
    "#         self.lin = nn.Linear(two_pow_k, k+1) #m1\n",
    "        self.lin = nn.Linear(two_pow_k, 1) #m2\n",
    "#         self.lin.weight.data = torch.tensor([[1.0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#                                         [0, 1, 1, 0, 1, 0, 0, 0],\n",
    "#                                         [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "#                                         [0, 1, 1, 1, 1, 1, 1, 1]])\n",
    "#         self.lin.bias.data = torch.tensor([0.0, -2, -5, -6])\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        immunity = nn.Hardtanh(0,1)(x)\n",
    "#         immunity = nn.Tanh()(2*x)\n",
    "        return immunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6e60a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel():\n",
    "\n",
    "    def __init__(self, model, device, learningRate, inputDim, epochs, batchSize):\n",
    "\n",
    "        self.device = device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=learningRate)\n",
    "        self.inputDim = inputDim\n",
    "        self.epochs = epochs\n",
    "        self.batchSize = batchSize\n",
    "\n",
    "    def train(self,):\n",
    "\n",
    "        pr_loss = -1234\n",
    "        flag = 1\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "#             input = torch.tensor([[1.0 if spec[0]==two_pow_k//2 else 0.0] + [1.0 if val==0 else 0.0 for val in spec[1:]] for spec in walsh_spectra[:pow(2, two_pow_k)//2]]).to(self.device) #unprocessed boolean function\n",
    "            input = torch.tensor([[1.0 if int(val)==0 else 0.0 for val in spec] for spec in walsh_spectra[:pow(2, two_pow_k)//2]]).to(self.device)\n",
    "            if(flag==1):\n",
    "                flag = 0\n",
    "                print(input.size())\n",
    "                print(\"input: \", input)\n",
    "            output = self.net(input)\n",
    "#             loss = F.mse_loss(ci, output) #m1\n",
    "#             loss = F.mse_loss(ci[:pow(2, two_pow_k)//8], output) #m1 for fraction of inputs as training data\n",
    "#             n = torch.Tensor.size(ci)[0]\n",
    "            loss = F.mse_loss(ci[:pow(2, two_pow_k)//2, 1].view(pow(2, two_pow_k)//2, 1), output) #m2 for fraction of input as training data\n",
    "#             loss = F.mse_loss(ci[:, 1].view(n, 1), output) #m2\n",
    "            loss.backward()\n",
    "            self.optimizer.step()    \n",
    "            if(epoch%200==199):\n",
    "                print(\"ep \", epoch, \", loss = \", loss)\n",
    "                if(abs(loss.item()-pr_loss)<0.00005):\n",
    "                    break\n",
    "                pr_loss = loss.item()\n",
    "\n",
    "    def train_batch(self,):\n",
    "\n",
    "        pr_loss = -1234\n",
    "        batchSize = self.batchSize\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            for step in range(((pow(2, two_pow_k) if self.inputDim<=16 else k*pow(2, 16))//2)//batchSize):\n",
    "#             for step in range((pow(2, (two_pow_k if self.inputDim<=4 else pow(2, 4)))//2)//batchSize):\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                input = torch.tensor([[1.0 if int(val)==0 else 0.0 for val in spec] for spec in walsh_spectra[step*batchSize:(step+1)*batchSize]]).to(self.device)\n",
    "                true_labels = ci[step*batchSize:(step+1)*batchSize, 1].view(batchSize, 1)\n",
    "                #up-sampling\n",
    "                ups_rate = 250\n",
    "                pos_samples = sum(ci[step*batchSize:(step+1)*batchSize, 1]).item()\n",
    "                true_labels = torch.cat((ci[step*batchSize:(step+1)*batchSize, 1].view(batchSize, 1), torch.ones(int(pos_samples)*ups_rate, 1)), 0)\n",
    "#                 print(pos_samples, true_labels.size(), true_labels[-5:])\n",
    "                up_sampled_input = torch.zeros(batchSize+int(pos_samples)*ups_rate, self.inputDim)\n",
    "                up_sampled_input[:batchSize] = input\n",
    "                app_ips = 0\n",
    "                for i in range(batchSize):\n",
    "                    if(int(ci[step*batchSize+i, 1].item())==1):\n",
    "                        for j in range(ups_rate):\n",
    "                            up_sampled_input[batchSize+app_ips+j] = input[i]\n",
    "                        app_ips += ups_rate\n",
    "                input = up_sampled_input\n",
    "                #upsampling-end\n",
    "                output = self.net(input)\n",
    "                loss = F.mse_loss(true_labels, output) #m2 for fraction of input as training data batch\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "            if(epoch%5==4 or epoch==0):\n",
    "                print(\"ep \", epoch, \", loss = \", loss)            \n",
    "                if(abs(loss.item()-pr_loss)<0.00005):\n",
    "                    break\n",
    "                pr_loss = loss.item()\n",
    "\n",
    "                \n",
    "    def test(self,n):\n",
    "        \n",
    "        test_samples = torch.tensor([[1.0 if int(val)==0 else 0.0 for val in spec] for spec in walsh_spectra[-n:]]).to(self.device)\n",
    "        preds = torch.round(self.net(test_samples))\n",
    "#         loss = F.mse_loss(ci[-n:], preds) #m1\n",
    "        loss = F.mse_loss(ci[-n:, 1].view(n, 1), preds) #m2\n",
    "        print(\"loss = \", loss)\n",
    "        for i in range(n):\n",
    "            if(not torch.equal(ci[-n+i][1], preds[i])):\n",
    "                print(ci[-n+i][1])\n",
    "                print(preds[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "817276b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0220,  0.9406,  0.9419, -0.0244,  0.9345, -0.0180, -0.0179,  0.0616]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.8295], requires_grad=True)\n",
      "Weights:  tensor([[-0., 1., 1., -0., 1., -0., -0., 0.]], grad_fn=<RoundBackward0>)\n",
      "Bias:  tensor([-2.], grad_fn=<RoundBackward0>)\n",
      "Using cpu device\n",
      "torch.Size([128, 8])\n",
      "input:  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "ep  199 , loss =  tensor(5.9660e-06, grad_fn=<MseLossBackward0>)\n",
      "ep  399 , loss =  tensor(4.3340e-08, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-4.3895e-04,  9.9873e-01,  9.9876e-01, -4.8695e-04,  9.9860e-01,\n",
      "         -3.5704e-04, -3.5279e-04,  1.2926e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.9964], requires_grad=True)\n",
      "Weights:  tensor([[-0., 1., 1., -0., 1., -0., -0., 0.]], grad_fn=<RoundBackward0>)\n",
      "Bias:  tensor([-2.], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.001\n",
    "epochs = 1200\n",
    "two_pow_k = pow(2, k)\n",
    "\n",
    "# model =  NeuralNetwork()\n",
    "print_model_weights(model)\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "trainer = TrainModel(model, device, learningRate, two_pow_k, epochs, two_pow_k)\n",
    "trainer.train()\n",
    "# trainer.train_batch()\n",
    "print_model_weights(model)\n",
    "# trainer.test(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "21ec6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(0., grad_fn=<MseLossBackward0>)\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(1.)\n",
      "tensor([1.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n",
      "tensor(0.)\n",
      "tensor([0.], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "trainer.test(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4f8c75ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744.0 1.0\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "two_pow_k = pow(2, k)\n",
    "\n",
    "count1, count2 = 0, 0\n",
    "for i in range(2500):\n",
    "    bf = [[1.0 if random.random()>0.5 else -1.0 for i in range(two_pow_k)] for i in range(400)]\n",
    "    walsh_spectra = torch.matmul(torch.tensor(bf), Had(two_pow_k))\n",
    "    ci = correlation_immunity(walsh_spectra)\n",
    "    count1 += sum(torch.tensor(ci)[:, 1])\n",
    "    count2 += sum(torch.tensor(ci)[:, 2])\n",
    "    \n",
    "print(count1.item(), count2.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "879e7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(0., grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# m = nn.Hardtanh(0, 1)\n",
    "# input = torch.tensor([-0.1, 0, 0.5, 1, 2, 3])\n",
    "# output = m(input)\n",
    "# print(output)\n",
    "\n",
    "# no_ones = []\n",
    "# for i in range(two_pow_k):\n",
    "#     no_ones.append(sum([int(dig) for dig in bin(i)[2:]]))\n",
    "# print(no_ones)\n",
    "# trainer.test(80)\n",
    "n = 256\n",
    "test_samples = torch.tensor([[1.0 if spec[0]==two_pow_k//2 else 0.0] + [1.0 if val==0 else 0.0 for val in spec[1:]] for spec in walsh_spectra[-n:]]).to(device)\n",
    "preds = torch.round(model(test_samples))\n",
    "# loss = F.mse_loss(ci[-n:], preds) #m1\n",
    "loss = F.mse_loss(ci[-n:, 1].view(n, 1), preds)\n",
    "print(\"loss = \", loss)\n",
    "for i in range(n):\n",
    "    if(not torch.equal(ci[-n+i][1], preds[i][0])):\n",
    "        print(ci[-n+i][1])\n",
    "        print(preds[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
