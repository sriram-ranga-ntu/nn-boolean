{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hadamard matrices\n",
    "\n",
    "H = {}\n",
    "H[4] = torch.tensor([[1.0, 1.0, 1.0, 1.0], [1.0, -1.0, 1.0, -1.0], [1.0, 1.0, -1.0, -1.0], [1.0, -1.0, -1.0, 1.0]])\n",
    "H[8] = torch.tensor([[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                            [1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0],\n",
    "                            [1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0],\n",
    "                            [1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0],\n",
    "                            [1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0],\n",
    "                            [1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0],\n",
    "                            [1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0]])\n",
    "\n",
    "\n",
    "f = open(\"had64.txt\")\n",
    "H64 = []\n",
    "for i in range(64):\n",
    "    H64.append([1.0 if i=='+' else -1.0 for i in list(f.readline())[:-1]])\n",
    "    \n",
    "H[64] = H64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated.\n"
     ]
    }
   ],
   "source": [
    "#Generating boolean functions and from them, their walsh spectra to feed as inputs to the neural network\n",
    "\n",
    "#k = number of variables in the boolean functions, n = number of inputs to train the model on\n",
    "def generate_input_data(k, n, scheme='regular'):\n",
    "    two_pow_k, data = pow(2, k), []\n",
    "    if(scheme=='regular'):\n",
    "        if(n<two_pow_k):\n",
    "            print(\"Requested number of inputs less than 2^k. Please request a higher number\")\n",
    "            return data\n",
    "        while(True):\n",
    "            if(two_pow_k<=16):\n",
    "                perm = torch.randperm(pow(2, two_pow_k))\n",
    "                data = [[0.0]*(two_pow_k-len(bin(num)[2:]))+[float(i) for i in bin(num)[2:]] for num in perm[:n]]\n",
    "            else:\n",
    "                data = [[0.0 if random.random()>0.5 else 1.0 for i in range(two_pow_k)] for i in range(n)]\n",
    "            rank = np.linalg.matrix_rank(data)\n",
    "            if(rank<two_pow_k):\n",
    "                print(\"Rank (\", rank, \") not large enough, generating data again\")\n",
    "            else:\n",
    "                data = torch.matmul(torch.tensor(data), H[two_pow_k])\n",
    "                print(\"Data generated.\")\n",
    "                break\n",
    "    elif(scheme=='one-hot'):\n",
    "        data = [[0.0]*i + [1.0] + [0.0]*(two_pow_k-i-1) for i in range(two_pow_k)]\n",
    "        data = torch.matmul(torch.tensor(data), H[two_pow_k])\n",
    "        print(\"Data generated\")\n",
    "    return data\n",
    "\n",
    "k = 3\n",
    "n = pow(2, pow(2, k))\n",
    "walsh_spectra = generate_input_data(k, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the correlation immunity of functions given their walsh spectra\n",
    "\n",
    "def correlation_immunity(walsh_spectra):\n",
    "    ci = []\n",
    "    n, two_pow_k = walsh_spectra.size()[0], walsh_spectra.size()[1]\n",
    "    k = int(math.log2(two_pow_k))\n",
    "    no_ones = []\n",
    "    for i in range(two_pow_k):\n",
    "        no_ones.append(sum([int(dig) for dig in bin(i)[2:]]))\n",
    "    for spectrum in walsh_spectra:\n",
    "        m_ci = [1]*(k+1)\n",
    "        for i in range(two_pow_k):\n",
    "            if(spectrum[i]!=0):\n",
    "                m_ci[no_ones[i]] = 0\n",
    "        m = 1\n",
    "        while(m<k+1 and m_ci[m]==1):\n",
    "            m+=1\n",
    "        m -= 1\n",
    "        # Let ci item = [x0, x1, ..., xm]. x0 is 1 if it is balanced, xi is 1 if it is i-correlation-immune\n",
    "        ci.append(([1.0] if spectrum[0]==two_pow_k//2 else [0.0])+(m)*[1.0]+(k-m)*[0.0])\n",
    "    return ci\n",
    "\n",
    "ci = torch.tensor(correlation_immunity(walsh_spectra))\n",
    "#temp\n",
    "ci = ci[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        two_pow_k = pow(2,k)\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(two_pow_k, two_pow_k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(two_pow_k, two_pow_k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(two_pow_k, two_pow_k),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(two_pow_k, two_pow_k),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(two_pow_k, k+1),\n",
    "            nn.Linear(two_pow_k, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        immunity = self.linear_stack(x)\n",
    "#         print(self.linear_stack(x))\n",
    "#         immunity = torch.tensor([[1.0 if imm<=0 else 0.0 for imm in inp] for inp in self.linear_stack(x)])\n",
    "        return immunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel():\n",
    "\n",
    "    def __init__(self, model, device, learningRate, inputDim, epochs):\n",
    "\n",
    "        self.device = device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr=learningRate)\n",
    "        self.inputDim = inputDim\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self,):\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            input = walsh_spectra.to(self.device)\n",
    "            output = self.net(input)\n",
    "            loss = F.mse_loss(torch.tensor(ci), output)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()      \n",
    "\n",
    "    def test(self,n):\n",
    "\n",
    "        test_samples = walsh_spectra.to(self.device)[:n]\n",
    "        preds = self.net(test_samples)\n",
    "        loss = F.mse_loss(torch.tensor(ci[:n]), preds)\n",
    "        print(\"loss = \", loss)\n",
    "        print(ci[:n])\n",
    "        print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1768032/3145797889.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = F.mse_loss(torch.tensor(ci), output)\n",
      "/tmp/ipykernel_1768032/3145797889.py:18: UserWarning: Using a target size (torch.Size([256, 1])) that is different to the input size (torch.Size([256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(torch.tensor(ci), output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(0.3089, grad_fn=<MseLossBackward0>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 1., 0., 1.])\n",
      "tensor([[0.2549],\n",
      "        [0.2860],\n",
      "        [0.2501],\n",
      "        [0.2738],\n",
      "        [0.2221],\n",
      "        [0.2824],\n",
      "        [0.2403],\n",
      "        [0.2654],\n",
      "        [0.2797],\n",
      "        [0.2275]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1768032/3145797889.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = F.mse_loss(torch.tensor(ci[:n]), preds)\n",
      "/tmp/ipykernel_1768032/3145797889.py:26: UserWarning: Using a target size (torch.Size([10, 1])) that is different to the input size (torch.Size([10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(torch.tensor(ci[:n]), preds)\n"
     ]
    }
   ],
   "source": [
    "learningRate = 0.001\n",
    "epochs = 1000\n",
    "two_pow_k = pow(2, k)\n",
    "\n",
    "# Additional Initializer\n",
    "model =  NeuralNetwork()\n",
    "trainer = TrainModel(model, device, learningRate, two_pow_k, epochs)\n",
    "trainer.train()\n",
    "trainer.test(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1112)\n",
      "tensor(-0.4742)\n",
      "tensor(-0.0088)\n",
      "tensor(-0.2912)\n",
      "tensor(-0.3992)\n",
      "tensor(-0.2360)\n",
      "tensor(-0.3728)\n",
      "tensor(-0.0220)\n",
      "tensor(-0.6030)\n",
      "tensor(-0.5197)\n",
      "tensor([[0., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([1., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 1., 1.])\n",
      "tensor([0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[ 3.3839e-02, -1.1122e-01, -4.7419e-01],\n",
    "        [-8.8419e-03, -2.9123e-01, -3.9918e-01],\n",
    "        [ 4.7317e-02, -2.3600e-01, -3.7276e-01],\n",
    "        [ 3.7765e-01, -2.1951e-02, -6.0302e-01],\n",
    "        [ 1.2820e-01,  6.2765e-02, -5.1973e-01]])\n",
    "\n",
    "# for i, inp in enumerate(x):\n",
    "for inp in x:\n",
    "    for imm in inp:\n",
    "        if(imm<=0):\n",
    "            print(imm)\n",
    "# immunity = torch.tensor([torch.tensor([1.0 if imm<=0 else 0.0 for imm in enumerate(inp)]) for inp in enumerate(x)])\n",
    "immunity = torch.tensor([[1.0 if imm<=0 else 0.0 for imm in inp] for inp in x])\n",
    "print(immunity)\n",
    "\n",
    "for x in immunity:\n",
    "    print(x)\n",
    "\n",
    "\n",
    "# print(len([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]))\n",
    "# print(walsh_spectra[240])\n",
    "# print(correlation_immunity(walsh_spectra)[240])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
