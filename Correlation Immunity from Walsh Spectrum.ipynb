{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hadamard matrices\n",
    "\n",
    "H = {}\n",
    "H[4] = torch.tensor([[1.0, 1.0, 1.0, 1.0], [1.0, -1.0, 1.0, -1.0], [1.0, 1.0, -1.0, -1.0], [1.0, -1.0, -1.0, 1.0]])\n",
    "H[8] = torch.tensor([[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "                            [1.0, -1.0, 1.0, -1.0, 1.0, -1.0, 1.0, -1.0],\n",
    "                            [1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0],\n",
    "                            [1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, 1.0],\n",
    "                            [1.0, 1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0],\n",
    "                            [1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0],\n",
    "                            [1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0],\n",
    "                            [1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0]])\n",
    "\n",
    "\n",
    "f = open(\"had64.txt\")\n",
    "H64 = []\n",
    "for i in range(64):\n",
    "    H64.append([1.0 if i=='+' else -1.0 for i in list(f.readline())[:-1]])\n",
    "    \n",
    "H[64] = H64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generated.\n"
     ]
    }
   ],
   "source": [
    "#Generating boolean functions and from them, their walsh spectra to feed as inputs to the neural network\n",
    "\n",
    "#k = number of variables in the boolean functions, n = number of inputs to train the model on\n",
    "def generate_input_data(k, n, scheme='regular'):\n",
    "    two_pow_k, data = pow(2, k), []\n",
    "    if(scheme=='regular'):\n",
    "        if(n<two_pow_k):\n",
    "            print(\"Requested number of inputs less than 2^k. Please request a higher number\")\n",
    "            return data\n",
    "        while(True):\n",
    "            if(two_pow_k<=16):\n",
    "                perm = torch.randperm(pow(2, two_pow_k))\n",
    "                data = [[0.0]*(two_pow_k-len(bin(num)[2:]))+[float(i) for i in bin(num)[2:]] for num in perm[:n]]\n",
    "            else:\n",
    "                data = [[0.0 if random.random()>0.5 else 1.0 for i in range(two_pow_k)] for i in range(n)]\n",
    "            rank = np.linalg.matrix_rank(data)\n",
    "            if(rank<two_pow_k):\n",
    "                print(\"Rank (\", rank, \") not large enough, generating data again\")\n",
    "            else:\n",
    "                data = torch.matmul(torch.tensor(data), H[two_pow_k])\n",
    "                print(\"Data generated.\")\n",
    "                break\n",
    "    elif(scheme=='one-hot'):\n",
    "        data = [[0.0]*i + [1.0] + [0.0]*(two_pow_k-i-1) for i in range(two_pow_k)]\n",
    "        data = torch.matmul(torch.tensor(data), H[two_pow_k])\n",
    "        print(\"Data generated\")\n",
    "    return data\n",
    "\n",
    "k = 3\n",
    "two_pow_k = pow(2, k)\n",
    "n = pow(2, two_pow_k)\n",
    "walsh_spectra = generate_input_data(k, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Immunity calculated\n"
     ]
    }
   ],
   "source": [
    "#Calculating the correlation immunity of functions given their walsh spectra\n",
    "\n",
    "def correlation_immunity(walsh_spectra):\n",
    "    ci = []\n",
    "    n, two_pow_k = walsh_spectra.size()[0], walsh_spectra.size()[1]\n",
    "    k = int(math.log2(two_pow_k))\n",
    "    no_ones = []\n",
    "    for i in range(two_pow_k):\n",
    "        no_ones.append(sum([int(dig) for dig in bin(i)[2:]]))\n",
    "    for spectrum in walsh_spectra:\n",
    "        m_ci = [1]*(k+1)\n",
    "        for i in range(two_pow_k):\n",
    "            if(spectrum[i]!=0):\n",
    "                m_ci[no_ones[i]] = 0\n",
    "        m = 1\n",
    "        while(m<k+1 and m_ci[m]==1):\n",
    "            m+=1\n",
    "        m -= 1\n",
    "        # Let ci item = [x0, x1, ..., xm]. x0 is 0 if it is balanced, xi is 1 if it is i-correlation-immune\n",
    "        ci.append(([1.0] if spectrum[0]==two_pow_k//2 else [0.0])+(m)*[1.0]+(k-m)*[0.0])\n",
    "    return ci\n",
    "\n",
    "ci = torch.tensor(correlation_immunity(walsh_spectra))\n",
    "print(\"Correlation Immunity calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        two_pow_k = pow(2,k)\n",
    "        self.lin = nn.Linear(two_pow_k, k+1)\n",
    "#         self.lin.weight.data = torch.tensor([[1.0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#                                         [0, 1, 1, 0, 1, 0, 0, 0],\n",
    "#                                         [0, 1, 1, 1, 1, 1, 1, 0],\n",
    "#                                         [0, 1, 1, 1, 1, 1, 1, 1]])\n",
    "#         self.lin.bias.data = torch.tensor([0.0, -2, -5, -6])\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        immunity = nn.Hardtanh(0, 1)(x)\n",
    "        return immunity\n",
    "\n",
    "# model =  NeuralNetwork()\n",
    "# weight_dict = OrderedDict(model.named_parameters())\n",
    "# print(weight_dict)\n",
    "# print(walsh_spectra[:15])\n",
    "# inp = torch.tensor([[1.0 if spec[0]==two_pow_k//2 else 0.0] + [1.0 if val==0 else 0.0 for val in spec[1:]] for spec in walsh_spectra[:15]])\n",
    "# print(inp)\n",
    "# out = model(inp)\n",
    "# for i in range(15):\n",
    "#     print(out[i], ci[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel():\n",
    "\n",
    "    def __init__(self, model, device, learningRate, inputDim, epochs):\n",
    "\n",
    "        self.device = device\n",
    "        self.net = model.to(self.device)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=learningRate)\n",
    "        self.inputDim = inputDim\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self,):\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            input = torch.tensor([[1.0 if spec[0]==two_pow_k//2 else 0.0] + [1.0 if val==0 else 0.0 for val in spec[1:]] for spec in walsh_spectra]).to(self.device)\n",
    "            output = self.net(input)\n",
    "            loss = F.mse_loss(ci, output)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()      \n",
    "\n",
    "    def test(self,n):\n",
    "        \n",
    "        test_samples = torch.tensor([[1.0 if spec[0]==two_pow_k//2 else 0.0] + [1.0 if val==0 else 0.0 for val in spec[1:]] for spec in walsh_spectra[-n:]]).to(self.device)\n",
    "        preds = torch.round(self.net(test_samples))\n",
    "        loss = F.mse_loss(ci[-n:], preds)\n",
    "        print(\"loss = \", loss)\n",
    "        print(ci[-n:])\n",
    "        print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[211], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m device\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TrainModel(model, device, learningRate, two_pow_k, epochs)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(\u001b[38;5;241m40\u001b[39m)\n",
      "Cell \u001b[0;32mIn[210], line 19\u001b[0m, in \u001b[0;36mTrainModel.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#             loss = F.mse_loss(ci, output)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m             loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mci\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m             loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:1169\u001b[0m, in \u001b[0;36mCrossEntropyLoss.__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m   1168\u001b[0m              reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index \u001b[38;5;241m=\u001b[39m ignore_index\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m=\u001b[39m label_smoothing\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:30\u001b[0m, in \u001b[0;36m_WeightedLoss.__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m, weight)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight: Optional[Tensor]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:23\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m=\u001b[39m reduction\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[0;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[1;32m     36\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "learningRate = 0.01\n",
    "epochs = 2000\n",
    "two_pow_k = pow(2, k)\n",
    "\n",
    "# Additional Initializer\n",
    "model =  NeuralNetwork()\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "trainer = TrainModel(model, device, learningRate, two_pow_k, epochs)\n",
    "trainer.train()\n",
    "trainer.test(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.0045e+00, -1.2289e-04, -3.6357e-04, -4.3695e-04, -4.5267e-04,\n",
      "         -4.3102e-04, -1.9332e-04, -1.3713e-04],\n",
      "        [ 9.7369e-08,  1.0000e+00,  1.0000e+00, -3.2380e-07,  1.0000e+00,\n",
      "          3.3894e-07, -3.3110e-07,  4.8111e-08],\n",
      "        [-2.5853e-01, -3.3823e-01, -2.5508e-01, -1.4343e-01, -1.9189e-01,\n",
      "          7.7660e-02,  7.2500e-02,  4.1680e-02],\n",
      "        [-2.4846e-01, -1.1852e-01,  1.2863e-01, -2.3546e-01, -8.2427e-02,\n",
      "         -2.2458e-02,  3.3191e-02,  1.1918e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.8670e-03, -2.0000e+00, -1.5452e-25, -4.7487e-02],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "weight_dict = OrderedDict(model.named_parameters())\n",
    "print(weight_dict['lin.weight'])\n",
    "print(weight_dict['lin.bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear_stack.0.weight', Parameter containing:\n",
      "tensor([[-0.1614,  0.0411, -0.1521, -0.2886,  0.2480, -0.2408,  0.0709,  0.0664],\n",
      "        [ 0.0220,  0.0802, -0.0709,  0.1610,  0.0594,  0.0637, -0.0524, -0.0143],\n",
      "        [-0.1557, -0.0862,  0.1195, -0.0795,  0.0290,  0.1450, -0.1094, -0.0919],\n",
      "        [-0.3567,  0.1902, -0.1556, -0.1234,  0.1328, -0.1280, -0.2085, -0.1013]],\n",
      "       requires_grad=True)), ('linear_stack.0.bias', Parameter containing:\n",
      "tensor([-0.2543, -0.2404, -0.1604, -0.2468], requires_grad=True))])\n",
      "tensor([ 4.,  0., -2.,  2., -2., -2.,  0.,  0.])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "weight_dict = OrderedDict(model.named_parameters())\n",
    "print(weight_dict)\n",
    "print(walsh_spectra[1])\n",
    "print(torch.tensor([[1 if val==0 else 0 for val in spec] for spec in walsh_spectra])[1])\n",
    "# x = torch.tensor([[ 3.3839e-02, -1.1122e-01, -4.7419e-01],\n",
    "#         [-8.8419e-03, -2.9123e-01, -3.9918e-01],\n",
    "#         [ 4.7317e-02, -2.3600e-01, -3.7276e-01],\n",
    "#         [ 3.7765e-01, -2.1951e-02, -6.0302e-01],\n",
    "#         [ 1.2820e-01,  6.2765e-02, -5.1973e-01]])\n",
    "\n",
    "# # for i, inp in enumerate(x):\n",
    "# for inp in x:\n",
    "#     for imm in inp:\n",
    "#         if(imm<=0):\n",
    "#             print(imm)\n",
    "# # immunity = torch.tensor([torch.tensor([1.0 if imm<=0 else 0.0 for imm in enumerate(inp)]) for inp in enumerate(x)])\n",
    "# immunity = torch.tensor([[1.0 if imm<=0 else 0.0 for imm in inp] for inp in x])\n",
    "# print(immunity)\n",
    "\n",
    "# for x in immunity:\n",
    "#     print(x)\n",
    "\n",
    "\n",
    "# print(len([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]))\n",
    "# print(walsh_spectra[240])\n",
    "# print(correlation_immunity(walsh_spectra)[240])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 1, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# m = nn.Hardtanh(0, 1)\n",
    "# input = torch.tensor([-0.1, 0, 0.5, 1, 2, 3])\n",
    "# output = m(input)\n",
    "# print(output)\n",
    "\n",
    "no_ones = []\n",
    "for i in range(two_pow_k):\n",
    "    no_ones.append(sum([int(dig) for dig in bin(i)[2:]]))\n",
    "print(no_ones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
